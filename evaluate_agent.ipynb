{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8294e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ray\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from ray.rllib.algorithms.impala import ImpalaConfig\n",
    "\n",
    "ImpalaTrainer = ImpalaConfig().build\n",
    "\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from env_trading import MultiAgentTradingEnv\n",
    "from model_architecture import SharedLSTMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69621d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTES: <class 'abc.ABCMeta'>\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.impala import ImpalaConfig\n",
    "\n",
    "print(\"ANTES:\", type(ImpalaConfig))  # Esperado: <class 'type'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3399ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3.10\n",
      "3.10.17 (main, Apr  9 2025, 08:54:14) [GCC 13.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dd507d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['training_iteration', 'episode_reward_mean', 'episode_len_mean'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m analysis\u001b[38;5;241m.\u001b[39mget_dataframe()\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_iteration\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepisode_reward_mean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepisode_len_mean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtail())\n",
      "File \u001b[0;32m~/mrl_hedging_uyen_pham_2021/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/mrl_hedging_uyen_pham_2021/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/mrl_hedging_uyen_pham_2021/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['training_iteration', 'episode_reward_mean', 'episode_len_mean'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "# Recria a função esperada pelo pickle\n",
    "def policy_mapping_fn(agent_id, episode, **kwargs):\n",
    "    return \"shared_policy\"\n",
    "\n",
    "with open(\"./results/impala_analysis.pkl\", \"rb\") as f:\n",
    "    analysis = pickle.load(f)\n",
    "\n",
    "df = analysis.get_dataframe()\n",
    "print(df[[\"training_iteration\", \"episode_reward_mean\", \"episode_len_mean\"]].tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(ignore_reinit_error=True, include_dashboard=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"shared_lstm_model\", SharedLSTMModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(env_config):\n",
    "    price_df = pd.read_csv(env_config[\"price_path\"], index_col=0)\n",
    "    return_df = pd.read_csv(env_config[\"return_path\"], index_col=0)\n",
    "    asset_types = env_config[\"asset_types\"]\n",
    "    return MultiAgentTradingEnv(\n",
    "        price_df=price_df,\n",
    "        log_return_df=return_df,\n",
    "        asset_types=asset_types,\n",
    "        initial_cash=env_config.get(\"initial_cash\", 1e6),\n",
    "        transaction_fee=env_config.get(\"transaction_fee\", 0.001),\n",
    "        future_discount=env_config.get(\"future_discount\", 0.001)\n",
    "    )\n",
    "\n",
    "register_env(\"MultiAgentTradingEnv-v0\", create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_path = \"./data/processed/price_data_eval.csv\"\n",
    "return_path = \"./data/processed/log_return_data_eval.csv\"\n",
    "checkpoint_path = \"./results/impala_trading_experiment/checkpoint_000100\"\n",
    "asset_types = [\"equity\"] * 10 + [\"future\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd37f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"env\": \"MultiAgentTradingEnv-v0\",\n",
    "    \"env_config\": {\n",
    "        \"price_path\": price_path,\n",
    "        \"return_path\": return_path,\n",
    "        \"asset_types\": asset_types,\n",
    "    },\n",
    "    \"framework\": \"torch\",\n",
    "    \"multiagent\": {\n",
    "        \"policies\": {\n",
    "            \"shared_policy\": (\n",
    "                None,\n",
    "                gym.spaces.Box(low=-np.inf, high=np.inf, shape=(3,), dtype=np.float32),\n",
    "                gym.spaces.Discrete(3),\n",
    "                {}\n",
    "            )\n",
    "        },\n",
    "        \"policy_mapping_fn\": lambda agent_id, episode, **kwargs: \"shared_policy\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"custom_model\": \"shared_lstm_model\",\n",
    "        \"max_seq_len\": 20,\n",
    "        \"custom_model_config\": {\n",
    "            \"lstm_cell_size\": 256\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "agent = ImpalaTrainer(config=config)\n",
    "agent.restore(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb493f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_env(config[\"env_config\"])\n",
    "obs = env.reset()\n",
    "done = {\"__all__\": False}\n",
    "\n",
    "portfolio_values = []\n",
    "dates = env.price_df.index\n",
    "\n",
    "while not done[\"__all__\"]:\n",
    "    actions = {}\n",
    "    for agent_id, agent_obs in obs.items():\n",
    "        action, _, _ = agent.compute_single_action(agent_obs, policy_id=\"shared_policy\")\n",
    "        actions[agent_id] = action\n",
    "    obs, rewards, done, info = env.step(actions)\n",
    "    prices = env.price_df.iloc[env.current_step].values\n",
    "    portfolio_value = env.cash + np.dot(env.positions, prices)\n",
    "    portfolio_values.append(portfolio_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(dates[:len(portfolio_values)], portfolio_values, label=\"RL Portfolio Value\")\n",
    "plt.title(\"Evolução do Portfólio do Agente RL\")\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Valor do Portfólio\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
