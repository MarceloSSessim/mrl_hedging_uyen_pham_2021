| File                            | Description                                                                                                                                                                                                                                                                                                                |
| ------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `01_data_preparation.ipynb`     | This notebook handles the acquisition and preprocessing of financial time series data from Vietnamese stock markets (HSX for stocks and HNX for futures). It computes daily returns for each asset, ensures data is cleaned and aligned, and prepares it in a format suitable for training a reinforcement learning agent. |
| `02_env_trading.py`             | This Python script defines the custom multi-agent trading environment using the `gym.Env` interface. It simulates realistic trading conditions including transaction fees, T+2 and T+0 settlement rules, and portfolio mark-to-market dynamics. It implements separate agents for equity and futures trading.              |
| `03_model_architecture.py`      | Defines the shared neural network architecture used by the IMPALA agents. This includes a combination of fully connected (dense) layers and LSTM units. The model outputs both policy logits and state value estimates, used by the actor-critic training method.                                                          |
| `04_train_impala.py`            | Main training script that configures and launches multi-agent training using the IMPALA algorithm with RLLib. It sets up the trainer, configures the number of workers, logging, hyperparameters, and initiates distributed training.                                                                                      |
| `05_evaluate_agent.ipynb`       | Loads a trained agent and simulates its behavior on out-of-sample data. The notebook records performance metrics, simulates long and short positions, and provides return visualizations across evaluation periods.                                                                                                        |
| `06_experiments_analysis.ipynb` | Compares the performance of the RL-based hedging strategy against standard baselines like buy-and-hold. It visualizes cumulative returns, analyzes risk-adjusted metrics, and highlights how the agent performs during market downturns.                                                                                   |

